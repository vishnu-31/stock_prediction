{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow pandas numpy matplotlib yahoo_fin sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                        STOCK PREDICTION USING TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                  LOADING DATA FOR THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "# Amazon stock market\n",
    "ticker = \"AAPL\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "129/129 [==============================] - ETA: 0s - loss: 6.3538e-04 - mean_absolute_error: 0.0144\n",
      "Epoch 00001: val_loss improved from inf to 0.00039, saving model to results/2021-12-14_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "129/129 [==============================] - 133s 946ms/step - loss: 6.3538e-04 - mean_absolute_error: 0.0144 - val_loss: 3.9134e-04 - val_mean_absolute_error: 0.0154\n",
      "Epoch 2/5\n",
      "129/129 [==============================] - ETA: 0s - loss: 2.4194e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 00002: val_loss improved from 0.00039 to 0.00031, saving model to results/2021-12-14_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "129/129 [==============================] - 85s 656ms/step - loss: 2.4194e-04 - mean_absolute_error: 0.0101 - val_loss: 3.0997e-04 - val_mean_absolute_error: 0.0087\n",
      "Epoch 3/5\n",
      "129/129 [==============================] - ETA: 0s - loss: 2.5040e-04 - mean_absolute_error: 0.0106\n",
      "Epoch 00003: val_loss improved from 0.00031 to 0.00014, saving model to results/2021-12-14_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "129/129 [==============================] - 82s 636ms/step - loss: 2.5040e-04 - mean_absolute_error: 0.0106 - val_loss: 1.4057e-04 - val_mean_absolute_error: 0.0055\n",
      "Epoch 4/5\n",
      "129/129 [==============================] - ETA: 0s - loss: 2.8594e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 00004: val_loss improved from 0.00014 to 0.00012, saving model to results/2021-12-14_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "129/129 [==============================] - 73s 563ms/step - loss: 2.8594e-04 - mean_absolute_error: 0.0121 - val_loss: 1.1601e-04 - val_mean_absolute_error: 0.0087\n",
      "Epoch 5/5\n",
      "129/129 [==============================] - ETA: 0s - loss: 2.2465e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 00005: val_loss improved from 0.00012 to 0.00011, saving model to results/2021-12-14_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "129/129 [==============================] - 75s 585ms/step - loss: 2.2465e-04 - mean_absolute_error: 0.0099 - val_loss: 1.1263e-04 - val_mean_absolute_error: 0.0107\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "\n",
    "# if os.exists(\"model1\"):\n",
    "  #   model = tf.keras.load_model(\"model1\")\n",
    "# else:\n",
    "    \n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model.save(\"model1\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL DIFFERENCE FROM THE PREDICTION\n",
    "\n",
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION FUNCTION\n",
    "\n",
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 170.80$\n",
      "huber_loss loss: 0.00011263052874710411\n",
      "Mean Absolute Error: 1.9525292416570106\n",
      "Accuracy score: 0.42043795620437957\n",
      "Total buy profit: 47.970091819763255\n",
      "Total sell profit: -412.1885821856557\n",
      "Total profit: -364.2184903658925\n",
      "Profit per trade: -0.17723527511722262\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  open        high         low       close    adjclose  \\\n",
      "2021-09-16  148.440002  148.970001  147.220001  148.789993  148.573151   \n",
      "2021-10-11  142.270004  144.809998  141.809998  142.809998  142.601883   \n",
      "2021-10-12  143.229996  143.250000  141.039993  141.509995  141.303772   \n",
      "2021-11-02  148.660004  151.570007  148.649994  150.020004  149.801376   \n",
      "2021-11-03  150.389999  151.970001  149.820007  151.490005  151.269241   \n",
      "2021-11-04  151.580002  152.429993  150.639999  150.960007  150.740005   \n",
      "2021-11-08  151.410004  151.570007  150.160004  150.440002  150.440002   \n",
      "2021-11-09  150.199997  151.429993  150.059998  150.809998  150.809998   \n",
      "2021-11-17  151.000000  155.000000  150.990005  153.490005  153.490005   \n",
      "2021-11-19  157.649994  161.020004  156.529999  160.550003  160.550003   \n",
      "\n",
      "               volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
      "2021-09-16   68034100   AAPL   149.814636        143.081177   -5.491974   \n",
      "2021-10-11   64452200   AAPL   141.008118        148.742920    0.000000   \n",
      "2021-10-12   73035900   AAPL   141.114075        149.801376    0.000000   \n",
      "2021-11-02   69122000   AAPL   148.315445        161.410004    0.000000   \n",
      "2021-11-03   54511500   AAPL   148.561249        161.940002    0.000000   \n",
      "2021-11-04   60394600   AAPL   148.897644        156.809998    0.000000   \n",
      "2021-11-08   55020900   AAPL   149.480881        165.300003    0.000000   \n",
      "2021-11-09   56787900   AAPL   149.618515        164.770004    0.000000   \n",
      "2021-11-17   88807000   AAPL   149.237366        174.559998    0.000000   \n",
      "2021-11-19  117305600   AAPL   151.560471        175.740005    0.000000   \n",
      "\n",
      "            sell_profit  \n",
      "2021-09-16     0.000000  \n",
      "2021-10-11    -6.141037  \n",
      "2021-10-12    -8.497604  \n",
      "2021-11-02   -11.608627  \n",
      "2021-11-03   -10.670761  \n",
      "2021-11-04    -6.069992  \n",
      "2021-11-08   -14.860001  \n",
      "2021-11-09   -13.960007  \n",
      "2021-11-17   -21.069992  \n",
      "2021-11-19   -15.190002  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
